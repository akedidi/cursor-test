import os
import glob
import csv
import statistics
import re
import logging
from collections import defaultdict
from datetime import datetime
from zipfile import ZipFile
import xml.etree.ElementTree as ET

from dotenv import load_dotenv
import xlsxwriter


# --------------------------------------------------------
# Logging
# --------------------------------------------------------
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s [%(levelname)s] %(message)s",
)

# Namespace WordprocessingML
W_NS = "http://schemas.openxmlformats.org/wordprocessingml/2006/main"
NS = {"w": W_NS}
ET.register_namespace("w", W_NS)

# Ordre des labels qu'on veut (Word + Excel)
LABEL_ORDER = [
    "Genera Token",   # Token
    "Purchase",
    "Policy",
    "Generate PDF",
    "Cancel",
]


# --------------------------------------------------------
# .env
# --------------------------------------------------------
def load_env():
    load_dotenv()

    results_folder = os.getenv("RESULTS_FOLDER")
    output_file = os.getenv("OUTPUT_FILE", "recap_scenarios.xlsx")
    doc_template = os.getenv("DOC_TEMPLATE")
    doc_output = os.getenv("DOC_OUTPUT")

    logging.info("RESULTS_FOLDER = %s", results_folder)
    logging.info("OUTPUT_FILE   = %s", output_file)
    logging.info("DOC_TEMPLATE  = %s", doc_template)
    logging.info("DOC_OUTPUT    = %s", doc_output)

    if not results_folder:
        raise ValueError("La variable RESULTS_FOLDER n'est pas définie dans le fichier .env")
    if not os.path.isdir(results_folder):
        raise ValueError(f"Le dossier RESULTS_FOLDER n'existe pas : {results_folder}")

    if os.path.isdir(output_file) or not os.path.splitext(output_file)[1]:
        output_file = os.path.join(output_file, "recap_scenarios.xlsx")
        logging.info("OUTPUT_FILE normalisé en : %s", output_file)

    return results_folder, output_file, doc_template, doc_output


# --------------------------------------------------------
# Recherche des fichiers
# --------------------------------------------------------
def extract_users_from_filename(path: str) -> int:
    """
    Ex : ...results-1-users.csv -> 1
         ...results-12-user.csv -> 12
    """
    name = os.path.basename(path)
    m = re.search(r"results-(\d+)-user", name)
    if m:
        return int(m.group(1))
    return 999999


def find_scenario_files(results_folder: str):
    pattern = os.path.join(results_folder, "IDP API-results-*user*.csv")
    logging.info("Recherche des fichiers avec le pattern : %s", pattern)
    files = glob.glob(pattern)

    if not files:
        raise FileNotFoundError(f"Aucun fichier trouvé avec le pattern : {pattern}")

    files = sorted(files, key=extract_users_from_filename)

    logging.info("Nombre de fichiers trouvés : %d", len(files))
    for f in files:
        logging.info(" - %s", f)

    return files


# --------------------------------------------------------
# Lecture CSV
# --------------------------------------------------------
def read_jmeter_csv(path: str):
    logging.info("Lecture du fichier CSV : %s", path)
    rows = []
    with open(path, newline="", encoding="utf-8") as f:
        reader = csv.DictReader(f)
        for r in reader:
            rows.append(r)
    logging.info("  -> %d lignes lues (hors en-tête)", len(rows))
    return rows


# --------------------------------------------------------
# Helpers
# --------------------------------------------------------
def to_float(value, default=None):
    try:
        return float(value)
    except Exception:
        return default


def to_int(value, default=0):
    try:
        return int(value)
    except Exception:
        return default


def to_bool_success(value):
    if value is None:
        return False
    v = str(value).strip().lower()
    return v in ("true", "1", "yes", "y")


def percentile(values, p):
    if not values:
        return None
    values = sorted(values)
    k = (len(values) - 1) * (p / 100.0)
    f = int(k)
    c = min(f + 1, len(values) - 1)
    if f == c:
        return values[int(k)]
    d0 = values[f] * (c - k)
    d1 = values[c] * (k - f)
    return d0 + d1


def compute_execution_range_string(rows):
    timestamps = []
    for r in rows:
        ts = r.get("timeStamp")
        if ts is None:
            continue
        try:
            timestamps.append(int(ts))
        except ValueError:
            continue

    if not timestamps:
        return ""

    start_ts = min(timestamps) / 1000.0
    end_ts = max(timestamps) / 1000.0

    start_dt = datetime.fromtimestamp(start_ts)
    end_dt = datetime.fromtimestamp(end_ts)

    fmt = "%d/%m/%y %I:%M %p"
    return f"{start_dt.strftime(fmt)} - {end_dt.strftime(fmt)}"


def xml_escape(text: str) -> str:
    if text is None:
        return ""
    return (
        str(text)
        .replace("&", "&amp;")
        .replace("<", "&lt;")
        .replace(">", "&gt;")
        .replace('"', "&quot;")
    )


# --------------------------------------------------------
# Calcul du recap par scénario
# --------------------------------------------------------
def compute_recap(rows):
    """
    Retourne une liste de dicts avec uniquement :
      Label, Samples, Average (ms), Min (ms), Max (ms), Std Dev (ms),
      Error %, Throughput (/min), Received KB/sec, Sent KB/sec, Avg Bytes
    (les 90/95/99% sont calculés mais pas stockés, donc pas visibles dans Excel)
    """
    logging.info("Calcul du tableau récapitulatif pour le scénario...")
    labels = {}

    for r in rows:
        label = r.get("label")
        elapsed_raw = r.get("elapsed")
        success_raw = r.get("success")
        ts_raw = r.get("timeStamp")

        if label is None or elapsed_raw is None or ts_raw is None:
            continue

        elapsed = to_float(elapsed_raw)
        if elapsed is None:
            continue

        ts = to_int(ts_raw)
        end_ts = ts + int(elapsed)

        success = to_bool_success(success_raw)
        bytes_val = to_int(r.get("bytes", 0))
        sent_bytes_val = to_int(r.get("sentBytes", 0))

        if label not in labels:
            labels[label] = {
                "times": [],
                "errors": 0,
                "bytes_sum": 0,
                "sent_bytes_sum": 0,
                "first_ts": ts,
                "last_end_ts": end_ts,
            }

        data = labels[label]
        data["times"].append(elapsed)
        if not success:
            data["errors"] += 1
        data["bytes_sum"] += bytes_val
        data["sent_bytes_sum"] += sent_bytes_val
        data["first_ts"] = min(data["first_ts"], ts)
        data["last_end_ts"] = max(data["last_end_ts"], end_ts)

    recap = []

    total_samples_all = 0
    all_times = []
    total_errors_all = 0
    total_bytes_all = 0
    total_sent_bytes_all = 0
    global_first_ts = None
    global_last_end_ts = None

    # ordre des labels pour Word/Excel
    ordered_labels = []
    for lbl in LABEL_ORDER:
        if lbl in labels:
            ordered_labels.append(lbl)
    for lbl in sorted(labels.keys()):
        if lbl not in ordered_labels:
            ordered_labels.append(lbl)

    for label in ordered_labels:
        data = labels[label]
        times = data["times"]
        errors = data["errors"]
        samples = len(times)
        if samples == 0:
            continue

        avg = statistics.mean(times)
        mn = min(times)
        mx = max(times)
        std_dev = statistics.pstdev(times) if samples > 1 else 0.0
        # percentiles calculés mais non stockés
        _ = percentile(times, 90)
        _ = percentile(times, 95)
        _ = percentile(times, 99)
        err_pct = (errors / samples * 100.0) if samples else 0.0

        # métriques JMeter : durée par label
        duration_ms = max(data["last_end_ts"] - data["first_ts"], 1)
        duration_sec = duration_ms / 1000.0
        duration_min = duration_sec / 60.0 if duration_sec > 0 else 0.0

        if duration_min > 0:
            throughput_per_min = samples / duration_min
            recv_kb_per_min = (data["bytes_sum"] / 1024.0) / duration_min
            sent_kb_per_min = (data["sent_bytes_sum"] / 1024.0) / duration_min
        else:
            throughput_per_min = 0.0
            recv_kb_per_min = 0.0
            sent_kb_per_min = 0.0

        avg_bytes = (data["bytes_sum"] / samples) if samples else 0.0

        recap.append({
            "Label": label,
            "Samples": samples,
            "Average (ms)": round(avg, 2),
            "Min (ms)": mn,
            "Max (ms)": mx,
            "Std Dev (ms)": round(std_dev, 2),
            "Error %": round(err_pct, 2),

            "Throughput (/min)": f"{throughput_per_min:.1f}/min",
            "Received KB/sec": round(recv_kb_per_min, 2),
            "Sent KB/sec": round(sent_kb_per_min, 2),
            "Avg Bytes": round(avg_bytes, 1),
        })

        total_samples_all += samples
        total_errors_all += errors
        all_times.extend(times)
        total_bytes_all += data["bytes_sum"]
        total_sent_bytes_all += data["sent_bytes_sum"]

        if global_first_ts is None or data["first_ts"] < global_first_ts:
            global_first_ts = data["first_ts"]
        if global_last_end_ts is None or data["last_end_ts"] > global_last_end_ts:
            global_last_end_ts = data["last_end_ts"]

    # TOTAL
    if all_times:
        total_avg = statistics.mean(all_times)
        total_min = min(all_times)
        total_max = max(all_times)
        total_std = statistics.pstdev(all_times) if len(all_times) > 1 else 0.0
        _ = percentile(all_times, 90)
        _ = percentile(all_times, 95)
        _ = percentile(all_times, 99)
        total_err_pct = (total_errors_all / total_samples_all * 100.0) if total_samples_all else 0.0

        if global_first_ts is not None and global_last_end_ts is not None:
            duration_ms_all = max(global_last_end_ts - global_first_ts, 1)
            duration_min_all = duration_ms_all / 1000.0 / 60.0
        else:
            duration_min_all = 0.0

        if duration_min_all > 0:
            throughput_all = total_samples_all / duration_min_all
            recv_kb_all = (total_bytes_all / 1024.0) / duration_min_all
            sent_kb_all = (total_sent_bytes_all / 1024.0) / duration_min_all
        else:
            throughput_all = 0.0
            recv_kb_all = 0.0
            sent_kb_all = 0.0

        avg_bytes_all = (total_bytes_all / total_samples_all) if total_samples_all else 0.0

        recap.append({
            "Label": "TOTAL",
            "Samples": total_samples_all,
            "Average (ms)": round(total_avg, 2),
            "Min (ms)": total_min,
            "Max (ms)": total_max,
            "Std Dev (ms)": round(total_std, 2),
            "Error %": round(total_err_pct, 2),

            "Throughput (/min)": f"{throughput_all:.1f}/min",
            "Received KB/sec": round(recv_kb_all, 2),
            "Sent KB/sec": round(sent_kb_all, 2),
            "Avg Bytes": round(avg_bytes_all, 1),
        })

    logging.info("  -> %d lignes dans le tableau récap (y compris TOTAL)", len(recap))
    return recap


# --------------------------------------------------------
# Excel – colonnes JMeter-like, SANS percentiles
# --------------------------------------------------------
def sanitize_sheet_name(name: str) -> str:
    name = re.sub(r'[:\\/?*\[\]]', "_", name)
    if len(name) > 31:
        name = name[:31]
    if not name:
        name = "Sheet"
    return name


def write_excel(output_file: str,
                scenarios_data: dict,
                scenarios_users: list,
                rt_matrix: dict,
                err_matrix: dict):
    logging.info("Création du fichier Excel : %s", output_file)
    workbook = xlsxwriter.Workbook(output_file)

    header_fmt = workbook.add_format({
        "bold": True,
        "bg_color": "#D9D9D9",
        "border": 1
    })
    cell_fmt = workbook.add_format({"border": 1})
    num_fmt = workbook.add_format({"border": 1, "num_format": "0.00"})
    int_fmt = workbook.add_format({"border": 1, "num_format": "0"})

    # colonnes type JMeter pour chaque scénario
    headers = [
        "Label",
        "# Samples",
        "Average",
        "Min",
        "Max",
        "Std. Dev.",
        "Error %",
        "Throughput",
        "Received KB/sec",
        "Sent KB/sec",
        "Avg. Bytes",
    ]

    col_key_map = {
        "Label": "Label",
        "# Samples": "Samples",
        "Average": "Average (ms)",
        "Min": "Min (ms)",
        "Max": "Max (ms)",
        "Std. Dev.": "Std Dev (ms)",
        "Error %": "Error %",
        "Throughput": "Throughput (/min)",
        "Received KB/sec": "Received KB/sec",
        "Sent KB/sec": "Sent KB/sec",
        "Avg. Bytes": "Avg Bytes",
    }

    # Feuilles par scénario
    for sheet_name_raw, rows in scenarios_data.items():
        sheet_name = sanitize_sheet_name(sheet_name_raw)
        logging.info("  -> Création de la feuille : %s", sheet_name)

        ws = workbook.add_worksheet(sheet_name)

        if not rows:
            logging.warning("    (Aucune donnée pour ce scénario)")
            continue

        for col, h in enumerate(headers):
            ws.write(0, col, h, header_fmt)

        for row_idx, row in enumerate(rows, start=1):
            for col_idx, h in enumerate(headers):
                key = col_key_map[h]
                val = row.get(key, "")
                if isinstance(val, (int, float)):
                    ws.write(row_idx, col_idx, val, num_fmt)
                else:
                    ws.write(row_idx, col_idx, str(val), cell_fmt)

        ws.set_column(0, 0, 40)
        ws.set_column(1, len(headers) - 1, 16)

    # Onglet Data Time Response Time (inchangé)
    ws_rt = workbook.add_worksheet("Data Time Response Time")
    ws_rt.write(0, 0, "Scenario", header_fmt)
    ws_rt.write(0, 1, "API", header_fmt)
    ws_rt.write(0, 2, "Response Time (ms)", header_fmt)

    row_idx = 1
    for users in sorted(scenarios_users):
        start_row = row_idx
        for label in LABEL_ORDER:
            val = rt_matrix.get(label, {}).get(users, None)
            if val is None:
                continue
            ws_rt.write(row_idx, 1, label, cell_fmt)
            ws_rt.write(row_idx, 2, int(round(val)), int_fmt)
            row_idx += 1
        end_row = row_idx - 1
        if end_row >= start_row:
            ws_rt.merge_range(start_row, 0, end_row, 0, users, int_fmt)

    ws_rt.set_column(0, 0, 12)
    ws_rt.set_column(1, 1, 20)
    ws_rt.set_column(2, 2, 20)

    # Onglet Data Error Rate (inchangé)
    ws_err = workbook.add_worksheet("Data Error Rate")
    ws_err.write(0, 0, "Scenario", header_fmt)
    ws_err.write(0, 1, "API", header_fmt)
    ws_err.write(0, 2, "Error Rate (%)", header_fmt)

    row_idx = 1
    for users in sorted(scenarios_users):
        start_row = row_idx
        for label in LABEL_ORDER:
            val = err_matrix.get(label, {}).get(users, None)
            if val is None:
                continue
            ws_err.write(row_idx, 1, label, cell_fmt)

            if abs(val - round(val)) < 1e-9:
                s = str(int(round(val)))
            else:
                s = f"{val:.2f}"
            ws_err.write(row_idx, 2, s, cell_fmt)

            row_idx += 1
        end_row = row_idx - 1
        if end_row >= start_row:
            ws_err.merge_range(start_row, 0, end_row, 0, users, int_fmt)

    ws_err.set_column(0, 0, 12)
    ws_err.set_column(1, 1, 20)
    ws_err.set_column(2, 2, 20)

    workbook.close()
    logging.info("Fichier Excel finalisé.")


# --------------------------------------------------------
# Word helpers – tableau JMeter-like
# --------------------------------------------------------
def build_response_time_table_xml(recap):
    """
    Table JMeter-like :
      Label, # Samples, Average, Min, Max, Std. Dev., Error %, Throughput,
      Received KB/sec, Sent KB/sec, Avg. Bytes
    """
    headers = [
        "Label",
        "# Samples",
        "Average",
        "Min",
        "Max",
        "Std. Dev.",
        "Error %",
        "Throughput",
        "Received KB/sec",
        "Sent KB/sec",
        "Avg. Bytes",
    ]

    header_row_xml = "<w:tr>"
    for h in headers:
        header_row_xml += f"""
        <w:tc>
          <w:tcPr/>
          <w:p>
            <w:r>
              <w:rPr>
                <w:b/>
                <w:sz w:val="16"/>
                <w:szCs w:val="16"/>
              </w:rPr>
              <w:t>{xml_escape(h)}</w:t>
            </w:r>
          </w:p>
        </w:tc>
        """
    header_row_xml += "</w:tr>"

    data_rows_xml = ""
    for r in recap:
        data_rows_xml += "<w:tr>"

        cells = [
            r["Label"],
            r["Samples"],
            r["Average (ms)"],
            r["Min (ms)"],
            r["Max (ms)"],
            r["Std Dev (ms)"],
            f"{r['Error %']:.2f}%",
            r["Throughput (/min)"],
            r["Received KB/sec"],
            r["Sent KB/sec"],
            r["Avg Bytes"],
        ]

        for val in cells:
            text = xml_escape(val)
            data_rows_xml += f"""
            <w:tc>
              <w:tcPr/>
              <w:p>
                <w:r>
                  <w:rPr>
                    <w:sz w:val="16"/>
                    <w:szCs w:val="16"/>
                  </w:rPr>
                  <w:t>{text}</w:t>
                </w:r>
              </w:p>
            </w:tc>
            """

        data_rows_xml += "</w:tr>"

    table_xml = f"""
    <w:tbl xmlns:w="{W_NS}">
      <w:tblPr>
        <w:tblBorders>
          <w:top w:val="single" w:sz="8" w:space="0" w:color="000000"/>
          <w:left w:val="single" w:sz="8" w:space="0" w:color="000000"/>
          <w:bottom w:val="single" w:sz="8" w:space="0" w:color="000000"/>
          <w:right w:val="single" w:sz="8" w:space="0" w:color="000000"/>
          <w:insideH w:val="single" w:sz="4" w:space="0" w:color="000000"/>
          <w:insideV w:val="single" w:sz="4" w:space="0" w:color="000000"/>
        </w:tblBorders>
      </w:tblPr>
      {header_row_xml}
      {data_rows_xml}
    </w:tbl>
    """
    return table_xml.strip()


def generate_word_report(template_path, output_path,
                         scenarios_users, scenario_recaps, scenario_rows):
    if not template_path:
        logging.warning("DOC_TEMPLATE non défini, génération Word ignorée.")
        return

    if not os.path.isfile(template_path):
        logging.error("DOC_TEMPLATE n'existe pas : %s", template_path)
        return

    logging.info("Ouverture du template Word (ZIP) : %s", template_path)

    with ZipFile(template_path, "r") as z:
        content = {name: z.read(name) for name in z.namelist()}

    if "word/document.xml" not in content:
        logging.error("word/document.xml introuvable dans le template.")
        return

    xml_bytes = content["word/document.xml"]
    root = ET.fromstring(xml_bytes)

    parent_map = {child: parent for parent in root.iter() for child in parent}

    # 1) Dates d'exécution
    exec_strings = []
    for users in sorted(scenarios_users):
        rows = scenario_rows.get(users, [])
        exec_strings.append(compute_execution_range_string(rows))

    for i, date_str in enumerate(exec_strings, start=1):
        placeholder = f"{{EXEC_DATE_{i}}}"
        found = False
        for t in root.findall(".//w:t", NS):
            if t.text == placeholder:
                t.text = date_str
                found = True
        if found:
            logging.info("Remplacement de %s par '%s'", placeholder, date_str)
        else:
            logging.info("Placeholder %s non trouvé dans le document.", placeholder)

    # 2) Tableaux Response time
    for idx, users in enumerate(sorted(scenarios_users), start=1):
        recap = scenario_recaps.get(users)
        if not recap:
            continue

        placeholder = f"{{RT_TABLE_{idx}}}"
        table_xml = build_response_time_table_xml(recap)
        table_el = ET.fromstring(table_xml)

        replaced = False
        for p in root.findall(".//w:p", NS):
            has_placeholder = False
            for t in p.findall(".//w:t", NS):
                if t.text == placeholder:
                    has_placeholder = True
                    break
            if not has_placeholder:
                continue

            parent = parent_map.get(p)
            if parent is None:
                continue

            idx_in_parent = list(parent).index(p)
            parent.remove(p)
            parent.insert(idx_in_parent, table_el)
            replaced = True
            logging.info("Tableau Response time inséré à la place de %s (users=%d)", placeholder, users)
            break

        if not replaced:
            logging.info("Placeholder %s non trouvé pour users=%d.", placeholder, users)

    new_xml_bytes = ET.tostring(root, encoding="utf-8", xml_declaration=True)

    with ZipFile(output_path, "w") as z:
        for name, data in content.items():
            if name == "word/document.xml":
                z.writestr(name, new_xml_bytes)
            else:
                z.writestr(name, data)

    logging.info("Document Word généré : %s", output_path)


# --------------------------------------------------------
# MAIN
# --------------------------------------------------------
def main():
    try:
        results_folder, output_file, doc_template, doc_output = load_env()
        files = find_scenario_files(results_folder)

        scenarios_data = {}
        scenarios_users = []
        rt_matrix = defaultdict(dict)
        err_matrix = defaultdict(dict)
        scenario_rows = {}
        scenario_recaps_by_users = {}

        for f in files:
            logging.info("--------------------------------------------------")
            logging.info("Traitement du fichier scénario : %s", f)

            users = extract_users_from_filename(f)
            if users not in scenarios_users:
                scenarios_users.append(users)

            rows = read_jmeter_csv(f)
            recap = compute_recap(rows)

            base_name = os.path.splitext(os.path.basename(f))[0]
            scenarios_data[base_name] = recap
            scenario_rows[users] = rows
            scenario_recaps_by_users[users] = recap

            for r in recap:
                if r["Label"] == "TOTAL":
                    continue
                label = r["Label"]
                rt_matrix[label][users] = r["Average (ms)"]
                err_matrix[label][users] = r["Error %"]

        write_excel(output_file, scenarios_data, scenarios_users, rt_matrix, err_matrix)

        if doc_template and doc_output:
            generate_word_report(doc_template, doc_output,
                                 scenarios_users, scenario_recaps_by_users, scenario_rows)
        else:
            logging.info("DOC_TEMPLATE ou DOC_OUTPUT non défini, Word ignoré.")

        logging.info("Terminé ✅")

    except Exception as e:
        logging.exception("❌ Erreur lors de l'exécution du script : %s", e)


if __name__ == "__main__":
    main()
